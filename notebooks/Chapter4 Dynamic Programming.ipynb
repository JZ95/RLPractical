{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3> Chapter3 is mainly about the threotical background in MDPs, thus is skipped. Today we will work several examples in textbook on DP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Word Example\n",
    "<font size=4> see textbook page 77 for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rlp.dynamic_programming.solver import JackCarRentalSolver, DPGridWorldSolver\n",
    "from rlp.dynamic_programming.base import JackCarRentalAgent, JackCarRentalEnv, DPGridWorldAgent, DPGridWorldEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rlp.grid_world import OFFSET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_dp_solver(rows, cols, terminals, gamma=0.99):\n",
    "    agent = DPGridWorldAgent(rows, cols, gamma)\n",
    "    env_model = DPGridWorldEnv(rows, cols, terminals)\n",
    "    solver = DPGridWorldSolver(agent, env_model)\n",
    "    stats = {}\n",
    "    for k in range(1):\n",
    "        solver.policy_eval(onestep=False)\n",
    "        solver.policy_improve()\n",
    "        values = solver.agent.V\n",
    "        policy = solver.agent.policy\n",
    "    \n",
    "        stats[k] = (values, policy)\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_grid_world_value(rows, cols, state_values):\n",
    "    \"\"\" draw value function in the grid world.\n",
    "    Params:\n",
    "    rows - number of rows\n",
    "    cols - number of columns\n",
    "    state_values - dict, value function of each entry in the grid world\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def draw_grid_world_policy(rows, cols, policy, mask_cell):\n",
    "    \"\"\" draw value function in the grid world.\n",
    "    Params:\n",
    "    rows - number of rows\n",
    "    cols - number of columns\n",
    "    policy - dict, distribution of directions at each entry in the grid world\n",
    "    \"\"\"\n",
    "    plt.subplot(aspect='equal')\n",
    "    plt.gca().invert_yaxis()\n",
    "\n",
    "    x = [-0.5 + i for i in range(rows + 1)]\n",
    "    y = [-0.5 + i for i in range(cols + 1)]\n",
    "    plt.xticks(x)\n",
    "    plt.yticks(y)\n",
    "    plt.grid(which='major', axis='both', linestyle='-', color='k', linewidth=1)\n",
    "    for cell in policy:\n",
    "        if cell in mask_cell:\n",
    "            continue\n",
    "        y, x = cell\n",
    "        for action, prob in policy[cell].items():\n",
    "            if prob != 0:\n",
    "                dy, dx = OFFSET[action]\n",
    "                plt.arrow(x, y, 0.25 * dx, 0.25 * dy, head_width=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = run_dp_solver(5, 5, [(0, 0), (4, 4)])\n",
    "draw_grid_world_policy(5, 5, stats[0][1], mask_cell=[(0, 0), (4, 4)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jack's Car Rental Problem\n",
    "<font size=4> see page 81."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = JackCarRentalAgent(discountRatio=0.9)\n",
    "env_model = JackCarRentalEnv((3, 4), (3, 2))\n",
    "solver = JackCarRentalSolver(agent, env_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_jack_car_rental_policy(policy):\n",
    "    plt.subplot(aspect='equal')\n",
    "    x_grid, y_grid = np.meshgrid(np.arange(21), np.arange(21))\n",
    "    policy_map = np.zeros_like(x_grid)\n",
    "    row, col = policy_map.shape\n",
    "    for i in range(row):\n",
    "        for j in range(col):\n",
    "            policy_map[i, j] = [k for k , v in policy[(i, j)].items() if v != 0][0]\n",
    "    plt.contour(x_grid, y_grid, policy_map)\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "stats = {}\n",
    "for k in range(5):\n",
    "    solver.policy_eval()\n",
    "    solver.policy_improve()\n",
    "    values = solver.agent.V\n",
    "    policy = solver.agent.policy\n",
    "\n",
    "    stats[k] = (values, policy)\n",
    "print('training using time %d min' % (time() - t0) / 3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_jack_car_rental_policy(stats[0][1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
